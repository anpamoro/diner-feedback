{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b0f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3360494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case: Channel</th>\n",
       "      <th>Question 1: Rate your Experience</th>\n",
       "      <th>Question 1a: How Can We Improve</th>\n",
       "      <th>Question 1b: Share What Went Well</th>\n",
       "      <th>Question 2: Easy Resolution?</th>\n",
       "      <th>Question 3: Follow Up Needed?</th>\n",
       "      <th>Country</th>\n",
       "      <th>Case Type</th>\n",
       "      <th>Case Sub Type</th>\n",
       "      <th>Date/Time Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chat</td>\n",
       "      <td>10</td>\n",
       "      <td>I just hope what Carlos advised works.  I do n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Reservations</td>\n",
       "      <td>Past Reservations</td>\n",
       "      <td>01.01.2024 15:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chat</td>\n",
       "      <td>10</td>\n",
       "      <td>So clear and concise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Loyalty</td>\n",
       "      <td>Resend Dining Rewards Gift Email</td>\n",
       "      <td>01.01.2024 16:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chat</td>\n",
       "      <td>10</td>\n",
       "      <td>Explained my problem and offered a solution.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Account</td>\n",
       "      <td>Privacy - Delete my Account</td>\n",
       "      <td>01.01.2024 16:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chat</td>\n",
       "      <td>10</td>\n",
       "      <td>The person was knowledgable, resolved my issue...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reservations</td>\n",
       "      <td>Cancellation/No-Show Dispute</td>\n",
       "      <td>01.01.2024 18:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chat</td>\n",
       "      <td>10</td>\n",
       "      <td>Quick fast knowledgable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reservations</td>\n",
       "      <td>Cancellation/No-Show Dispute</td>\n",
       "      <td>01.01.2024 19:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case: Channel  Question 1: Rate your Experience  \\\n",
       "0          Chat                                10   \n",
       "1          Chat                                10   \n",
       "2          Chat                                10   \n",
       "3          Chat                                10   \n",
       "4          Chat                                10   \n",
       "\n",
       "                     Question 1a: How Can We Improve  \\\n",
       "0  I just hope what Carlos advised works.  I do n...   \n",
       "1                               So clear and concise   \n",
       "2       Explained my problem and offered a solution.   \n",
       "3  The person was knowledgable, resolved my issue...   \n",
       "4                            Quick fast knowledgable   \n",
       "\n",
       "  Question 1b: Share What Went Well  Question 2: Easy Resolution?  \\\n",
       "0                               NaN                           NaN   \n",
       "1                               NaN                           NaN   \n",
       "2                               NaN                           NaN   \n",
       "3                               NaN                           NaN   \n",
       "4                               NaN                           NaN   \n",
       "\n",
       "  Question 3: Follow Up Needed?        Country     Case Type  \\\n",
       "0                           NaN  United States  Reservations   \n",
       "1                           NaN            NaN       Loyalty   \n",
       "2                           NaN            NaN    My Account   \n",
       "3                           NaN            NaN  Reservations   \n",
       "4                           NaN            NaN  Reservations   \n",
       "\n",
       "                      Case Sub Type Date/Time Created  \n",
       "0                 Past Reservations  01.01.2024 15:49  \n",
       "1  Resend Dining Rewards Gift Email  01.01.2024 16:08  \n",
       "2       Privacy - Delete my Account  01.01.2024 16:24  \n",
       "3      Cancellation/No-Show Dispute  01.01.2024 18:22  \n",
       "4      Cancellation/No-Show Dispute  01.01.2024 19:14  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Diner CSat Raw Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcb536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('helpful', 295), ('issue', 196), ('chat', 133), ('agent', 130), ('problem', 114), ('great', 114), ('quick', 96), ('service', 95), ('help', 92), ('account', 84), ('customer', 84), ('get', 84), ('resolved', 77), ('points', 73), ('person', 67), ('thank', 67), ('able', 66), ('easy', 65), ('live', 62), ('quickly', 60)]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column\n",
    "all_comments = ' '.join(df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words and filter stopwords and punctuation\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))  # You can adjust the language as per your requirement\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Count word frequency\n",
    "word_freq = Counter(tokens)\n",
    "\n",
    "# Print the most common words\n",
    "print(word_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d939f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chat', 28), ('service', 22), ('customer', 20), ('issue', 17), ('agent', 15), ('could', 15), ('ended', 13), ('table', 13), ('reservation', 12), ('open', 12), ('points', 12), ('help', 11), ('problem', 11), ('person', 11), ('account', 10), ('live', 10), ('get', 10), ('restaurant', 9), ('asked', 9), ('question', 9)]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Question 1: Rate your Experience' is equal to 1\n",
    "filtered_df = df[df['Question 1: Rate your Experience'] == 1]\n",
    "\n",
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column for filtered rows\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words and filter stopwords and punctuation\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))  # You can adjust the language as per your requirement\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Count word frequency\n",
    "word_freq = Counter(tokens)\n",
    "\n",
    "# Print the most common words\n",
    "print(word_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802a50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2499b57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('customer', 'service'), ('open', 'table'), ('ended', 'chat'), ('agent', 'ended'), ('resolve', 'issue'), ('worst', 'customer'), ('chat', 'ended'), ('phone', 'number'), ('20', 'minutes'), ('asked', 'help')]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Question 1: Rate your Experience' is equal to 1\n",
    "filtered_df = df[df['Question 1: Rate your Experience'] == 1]\n",
    "\n",
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column for filtered rows\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words and filter stopwords and punctuation\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Calculate bigrams (pairs of consecutive words)\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common bigrams\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "top_bigrams = finder.nbest(bigram_measures.raw_freq, 10)\n",
    "\n",
    "# Print the top bigrams\n",
    "print(top_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db156ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a3ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('very', 'helpful', 'and') 52\n",
      "('was', 'very', 'helpful') 49\n",
      "('.', 'thank', 'you') 33\n",
      "('was', 'able', 'to') 31\n",
      "('.', 'very', 'helpful') 29\n",
      "('very', 'helpful', '.') 21\n",
      "('the', 'agent', 'was') 20\n",
      "('resolve', 'my', 'issue') 19\n",
      "('thank', 'you', '!') 18\n",
      "('my', 'issue', '.') 18\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column\n",
    "all_comments = ' '.join(df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Calculate trigrams (sets of three consecutive words)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common trigrams\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_trigrams = finder.nbest(trigram_measures.raw_freq, 10)  # Adjust '10' as needed\n",
    "\n",
    "# Count the frequency of each trigram in the text\n",
    "trigram_freq = finder.ngram_fd.items()\n",
    "\n",
    "# Print the top trigrams with their frequencies\n",
    "for trigram, freq in sorted(trigram_freq, key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(trigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87930a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('agent', 'ended', 'chat') 5\n",
      "('worst', 'customer', 'service') 5\n",
      "('poor', 'customer', 'service') 3\n",
      "('ended', 'chat', 'could') 2\n",
      "('terrible', 'customer', 'service') 2\n",
      "('ended', 'chat', 'without') 2\n",
      "('help', 'resolve', 'issue') 2\n",
      "('ended', 'chat', 'finished') 1\n",
      "('chat', 'finished', 'discussing') 1\n",
      "('finished', 'discussing', 'issue') 1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Question 1: Rate your Experience' is equal to 1\n",
    "filtered_df = df[df['Question 1: Rate your Experience'] == 1]\n",
    "\n",
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column for filtered rows\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words and filter stopwords and punctuation\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Calculate trigrams (sets of three consecutive words)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common trigrams\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_trigrams = finder.nbest(trigram_measures.raw_freq, 10)\n",
    "\n",
    "# Count the frequency of each trigram in the text\n",
    "trigram_freq = finder.ngram_fd.items()\n",
    "\n",
    "# Print the top trigrams with their frequencies\n",
    "for trigram, freq in sorted(trigram_freq, key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(trigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ac693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('great', 'customer', 'service') 10\n",
      "('able', 'resolve', 'issue') 6\n",
      "('helpful', 'resolved', 'issue') 6\n",
      "('customer', 'service', 'quick') 5\n",
      "('customer', 'service', 'representative') 5\n",
      "('get', 'live', 'chat') 5\n",
      "('resolved', 'issue', 'quickly') 4\n",
      "('solved', 'problem', 'quickly') 4\n",
      "('took', 'care', 'problem') 4\n",
      "('excellent', 'customer', 'service') 4\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Question 1: Rate your Experience' is equal to 1\n",
    "filtered_df = df[df['Question 1: Rate your Experience'] == 10]\n",
    "\n",
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column for filtered rows\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words and filter stopwords and punctuation\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Calculate trigrams (sets of three consecutive words)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common trigrams\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_trigrams = finder.nbest(trigram_measures.raw_freq, 10)\n",
    "\n",
    "# Count the frequency of each trigram in the text\n",
    "trigram_freq = finder.ngram_fd.items()\n",
    "\n",
    "# Print the top trigrams with their frequencies\n",
    "for trigram, freq in sorted(trigram_freq, key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(trigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de0b039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('took', 'long', 'time') 2\n",
      "('good', 'person', 'kind') 1\n",
      "('person', 'kind', 'restored') 1\n",
      "('kind', 'restored', 'points') 1\n",
      "('restored', 'points', 'able') 1\n",
      "('points', 'able', 'navigate') 1\n",
      "('able', 'navigate', 'beyond') 1\n",
      "('navigate', 'beyond', 'automated') 1\n",
      "('beyond', 'automated', 'chatbot') 1\n",
      "('automated', 'chatbot', 'representative') 1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Question 1: Rate your Experience' is equal to 1\n",
    "filtered_df = df[df['Question 1: Rate your Experience'] == 9]\n",
    "\n",
    "# Concatenate all comments from the 'Question 1a: How Can We Improve' column for filtered rows\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words and filter stopwords and punctuation\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Calculate trigrams (sets of three consecutive words)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common trigrams\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_trigrams = finder.nbest(trigram_measures.raw_freq, 10)\n",
    "\n",
    "# Count the frequency of each trigram in the text\n",
    "trigram_freq = finder.ngram_fd.items()\n",
    "\n",
    "# Print the top trigrams with their frequencies\n",
    "for trigram, freq in sorted(trigram_freq, key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(trigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514b323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('help', 'resolve', 'issue') 1\n",
      "('able', 'resolve', 'issue') 1\n",
      "('customer', 'service', 'agent') 1\n",
      "('agent', 'ended', 'chat') 1\n",
      "('excellent', 'customer', 'service') 1\n",
      "('friendly', 'quick', 'respond') 1\n",
      "('get', 'live', 'chat') 1\n",
      "('great', 'customer', 'service') 1\n",
      "('resolved', 'issue', 'quickly') 1\n",
      "('able', 'help', 'resolve') 1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Case Type' is 'My Account'\n",
    "filtered_df = df[df['Case Type'] == 'My Account']\n",
    "\n",
    "# Concatenate all comments from the filtered rows in 'Question 1a: How Can We Improve' column\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Calculate trigrams (sets of three consecutive words)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common trigrams\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_trigrams = finder.nbest(trigram_measures.raw_freq, 10)  # Adjust '10' as needed\n",
    "\n",
    "# Print the top trigrams\n",
    "for trigram in top_trigrams:\n",
    "    print(trigram, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c80e2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('great', 'customer', 'service') 3\n",
      "('help', 'resolve', 'issue') 3\n",
      "('excellent', 'customer', 'service') 3\n",
      "('resolved', 'issue', 'quickly') 3\n",
      "('get', 'live', 'chat') 3\n",
      "('solved', 'problem', 'quickly') 2\n",
      "('helpful', 'took', 'care') 2\n",
      "('able', 'resolve', 'issue') 2\n",
      "('hard', 'come', 'days') 2\n",
      "('took', 'care', 'problem') 2\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Case Type' is 'My Account' and 'Question 1: Rate your Experience' is 1\n",
    "filtered_df = df[(df['Case Type'] == 'My Account') & (df['Question 1: Rate your Experience'] == 10)]\n",
    "\n",
    "# Concatenate all comments from the filtered rows in 'Question 1a: How Can We Improve' column\n",
    "all_comments = ' '.join(filtered_df['Question 1a: How Can We Improve'].dropna())\n",
    "\n",
    "# Tokenize words\n",
    "tokens = word_tokenize(all_comments.lower())  # Convert to lowercase for accurate counting\n",
    "\n",
    "# Filter stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "# Calculate trigrams (sets of three consecutive words)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Apply a frequency filter to find the most common trigrams\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_trigrams = finder.ngram_fd.items()\n",
    "\n",
    "# Sort trigrams by frequency in descending order\n",
    "sorted_trigrams = sorted(top_trigrams, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print the top trigrams with their frequencies\n",
    "for trigram, freq in sorted_trigrams[:10]:  # Adjust '10' as needed\n",
    "    print(trigram, freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
